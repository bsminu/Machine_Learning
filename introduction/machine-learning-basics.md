# Machine Learning Basics

## Introduction

This is the era of the Industrial Revolution. Machines have come a long way. For computers to understand what to do, we need to provide a program. Program is nothing but a list of instructions written in a language, i.e Python, R, C++ etc, which a computer can execute. Program consists of algorithms which are a list of rules to follow in order to solve a problem.

**Machine learning** is nothing but learning from existing data and predict on the unseen/new data. Using a learning algorithm, the computer finds patterns in the training data. The output of the training process is a machine learning model which you can then use to make predictions.

![Machine Learning](https://lh4.googleusercontent.com/gCrHyXJdEjb9mKRt2efpK3aisNNVywD5jd7N6owhALIPvYkUCHjYtVN6KQMyhNFPtuFkiD8szJv0fWYX9Bf4IpyriF6RAFxiouQTV47hR9MbQSdgob6NN3Q91hiujnmLWYCRZkVL)

## **Difference between Statistics and Machine Learning**

Statistics models are designed for inference about the relationships between variables. Machine Learning models are designed to make the most accurate predictions.  Statistics is based on assumptions. Machine Learning is based on rules.



## **Machine Learning project flow**

![Machine Learning Project workflow](https://lh4.googleusercontent.com/WowH3GjAu9BHj0aknZhYGU7iypwbJEPHO8Qju93lKpxbi654y2AgNm9D794tzE8r2_mtJTtGNZ-h_ze_zihqgJqlpdOKEGDx5KNJGR2lV6Xgbw0pi0OHrRgxn-edu2PCqmSU76xq)

## **Key Terminologies**

Training data : Data used to fit the model 

Testing data :  Data used to evaluate the model

Validation data : Data used for tuning the model

Features \(independent variables\) : inputs used for training a model

Labels \(dependent variables\): what we are predicting

Labeled data : Data contains both features and labels

Unlabeled data : Data contains features , but no labels

Model : The output of ‘algorithm runs on the data’. 

Algorithm : Set of steps to do a specific task.

Modeling :  process of incorporating information into a tool which can forecast and make predictions.  

Generalization : Model’s ability to give sensible outputs to sets of input that it has never seen before. A model that generalizes well is a model that is neither underfit nor overfit.

Overfitting : Overfitting is the case where the generalization of the model is unreliable. This is due to the model learning “too much” from the training data set. Reduce the training time, training data, etc can 

Underfitting : Underfitting is the case where the model has “ not learned enough” from the training data, resulting in low generalization and unreliable predictions.  


![Machine Learning Process](https://lh5.googleusercontent.com/e66VHdAkvLxdRMNC1rDAPhh7FsUGMBQTR-0yL1Pe8D9GSCh9pbf_95skYGDuEJcq0NnixIZuvjyz8Rmcvt9_0DbKsINlL3wgq3gRdUhoKPL6uy_A00L_K0KtspfE3A9dPXK3Iv9v)

We split the data into two parts - training and testing data. Training data is used to build the model and testing data to test the model’s performance.  
  


